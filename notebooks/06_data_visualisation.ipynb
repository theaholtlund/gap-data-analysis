{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising Retrieved Data\n",
    "\n",
    "This Jupyter Notebook is for visualising core components of the data generated from the previous notebooks, to point out key attributes and relationships in the data. This could be helpful in assisting redistribution managers in better understanding what trends, dependencies and relationships exist, which could be useful for prioritising and decision-making in the redistribution process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules and libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Get current working directory and append parent directory for module imports\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Import modules from other project scripts\n",
    "from data_constants import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions to Visualise Extracted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_author_labels(data_dict: dict) -> dict:\n",
    "    \"\"\"Takes a dict and returns a new dict that maps each key to a label, where they are identified \n",
    "    as \"user\" and then a letter in alphabetic order (\"user a\" for the first key, \"user b\" for the second key and so on). \n",
    "    This is to avoid displaying long hash values when plotting data, as it compromises readability.\n",
    "\n",
    "    Args:\n",
    "        data_dict (dict): Input dict for which labels are to be created.\n",
    "\n",
    "    Returns:\n",
    "        dict: New dict mapping each key to a user label in alphabetic order.\n",
    "    \"\"\"\n",
    "    labels = {}\n",
    "    for idx, key in enumerate(data_dict.keys()):\n",
    "        label = f\"User {chr(97 + idx)}\"\n",
    "        labels[key] = label\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pie_chart(data: dict, title: str) -> None:\n",
    "    \"\"\"Plot a pie chart for the given data.\n",
    "\n",
    "    Args:\n",
    "        data (dict): The data to plot. The keys represent the categories,\n",
    "        and the values represent the corresponding values for each category.\n",
    "        title (str): The title of the plot.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pie(data.values(), labels=data.keys(), autopct='%1.1f%%', startangle=140, colors=sns.color_palette(\"pastel\"))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(data: list, title: str, x_label: str, bins: int = 10) -> None:\n",
    "    \"\"\"Plot a histogram for the given data.\n",
    "\n",
    "    Args:\n",
    "        data (list): A list containing the data to plot.\n",
    "        title (str): The title of the plot.\n",
    "        x_label (str): The label for the x-axis.\n",
    "        bins (int): The number of bins for the histogram.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(data, bins=bins, color='#ffb86e', rwidth=0.8)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel('Number of Repositories')\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_chart(data: dict, title: str, x_label: str, y_label: str) -> None:\n",
    "    \"\"\"Plot a bar chart using the given data.\n",
    "\n",
    "    Args:\n",
    "        data (dict): The data to plot. The keys represent the categories on the x-axis, \n",
    "        and the values represent the corresponding values on the y-axis.\n",
    "        title (str): The title of the plot.\n",
    "        x_label (str): The label for the x-axis.\n",
    "        y_label (str): The label for the y-axis.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(data.keys(), data.values(), color='#ffb86e')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_collaborations(community_data: dict, top_n_users: int) -> None:\n",
    "    \"\"\"Plots collaborations between authors and submitters in the GAP community.\n",
    "\n",
    "    Parameters:\n",
    "        community_data (dict): A dict containing community data with authors, submitters and interactions.\n",
    "        top_n_users (int): The number of submitters to be included in the plot.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    # Add nodes for authors and submitters\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(community_data[\"authors\"], node_type=\"author\")\n",
    "    G.add_nodes_from(community_data[\"submitters\"], node_type=\"submitter\")\n",
    "\n",
    "    # Add edges for collaborations between authors and submitters\n",
    "    for author, submitters in community_data[\"interactions\"].items():\n",
    "        for submitter in submitters:\n",
    "            if author in G.nodes and submitter in G.nodes:\n",
    "                G.add_edge(submitter, author)\n",
    "\n",
    "    # Get the top_n submitters based on collaboration frequency\n",
    "    submitter_collaborations = {submitter: sum(1 for authors in community_data[\"interactions\"].values() if submitter in authors) for submitter in G.nodes if G.nodes[submitter][\"node_type\"] == \"submitter\"}\n",
    "    top_n_submitters = sorted(submitter_collaborations, key=submitter_collaborations.get, reverse=True)[:top_n_users]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    pos = nx.spring_layout(G, seed=42, k=1)\n",
    "\n",
    "    # Draw nodes with different colours for the submitters, while authors are always red\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=[node for node in G.nodes if G.nodes[node][\"node_type\"] == \"author\"], node_size=200, node_color=\"red\", alpha=0.7, label=\"Authors\")\n",
    "    for i, submitter in enumerate(top_n_submitters):\n",
    "        node_colour = f\"C{i}\"\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=[submitter], node_size=200, node_color=node_colour, alpha=0.7, label=\"Submitters\")\n",
    "\n",
    "        # Draw coloured lines to show collaborations with each submitter\n",
    "        edges = G.edges()\n",
    "        colour_edges = [(u, v) for u, v in edges if G.nodes[u][\"node_type\"] == \"submitter\" and G.nodes[v][\"node_type\"] == \"author\" and u == submitter]\n",
    "        nx.draw_networkx_edges(G, pos, edgelist=colour_edges, edge_color=node_colour, arrowsize=5, alpha=0.5)\n",
    "\n",
    "    plt.title(f\"Interactions between Authors and Top {top_n_users} Issue Submitters\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.text(0.8, 0.95, \"Red: Authors\\nColoured Nodes: Submitters\\nColoured Lines: Interactions\", transform=plt.gca().transAxes, fontsize=12, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"white\", alpha=0.7))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyse and Visualise Extracted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables to regulate the scope for certain user and repository visualisations\n",
    "top_n_repos = 10\n",
    "top_n_users = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the repository data from the JSON file\n",
    "data_folder = \"collected_data\"\n",
    "repo_file_path = os.path.join(data_folder, \"repo_data.json\")\n",
    "repo_data = load_data(repo_file_path)\n",
    "\n",
    "# Load monitoring data from the JSON file\n",
    "monitoring_file_path = os.path.join(data_folder, \"monitoring_data.json\")\n",
    "monitoring_data = load_data(monitoring_file_path)\n",
    "\n",
    "# Load testing data from the JSON file\n",
    "testing_file_path = os.path.join(data_folder, \"testing_data.json\")\n",
    "testing_data = load_data(testing_file_path)\n",
    "\n",
    "# Load community data from the JSON file\n",
    "community_file_path = os.path.join(data_folder, \"community_data.json\")\n",
    "community_data = load_data(community_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Repository Data: Visualising Key Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display key metrics for repositories based on their current state\n",
    "# Show the distribution of reposiroties by age, measured in years\n",
    "repo_ages = [repo['age_in_days'] / 365 for repo in repo_data]\n",
    "plot_histogram(repo_ages, \"Distribution of Repositories by Age\", \"Age in Years\")\n",
    "\n",
    "# Show the distribution of repositories by total releases\n",
    "total_releases = [repo['total_releases'] for repo in repo_data]\n",
    "plot_histogram(total_releases, \"Distribution of Repositories by Total Releases\", \"Number of Releases\")\n",
    "\n",
    "# Show the distribution of repositories by open issues\n",
    "open_issues = {repo['repo']: repo['open_issues_count'] for repo in repo_data}\n",
    "open_issues = dict(sorted(open_issues.items(), key=lambda item: item[1], reverse=True)[:top_n_repos])\n",
    "plot_bar_chart(open_issues, \"Distribution of Top {} Repositories by Open Issues\".format(top_n_repos), \"Repository\", \"Number of Open Issues\")\n",
    "\n",
    "# Show the distribution of repositories by open and closed pull requests\n",
    "open_prs = sum([repo['open_pull_requests'] for repo in repo_data])\n",
    "closed_prs = sum([repo['closed_pull_requests'] for repo in repo_data])\n",
    "plot_pie_chart({'Open PRs': open_prs, 'Closed PRs': closed_prs}, \"Distribution of Pull Requests (Open vs. Closed)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Monitoring Data: Visualising Key Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define monitoring data for visualisation\n",
    "packages_with_different_versions = monitoring_data.get('packages_with_different_versions', [])\n",
    "all_previous_and_maybe_next = monitoring_data.get('all_previous_and_maybe_next', [])\n",
    "previous_and_maybe_next_labels = monitoring_data.get('previous_and_maybe_next_labels', [])\n",
    "\n",
    "# Plot to show next releases, in last release and maybe in the next, and in last release and maybe in the next based on labels\n",
    "# The labels in question are \"automatic pr\", \"new package\" and \"update package\"\n",
    "status_count = {\n",
    "    'Previous and Maybe Next': len(all_previous_and_maybe_next),\n",
    "    'Previous and Maybe Next Labels': len(previous_and_maybe_next_labels),\n",
    "    'In Next Release': len(packages_with_different_versions),\n",
    "}\n",
    "\n",
    "# Create a bar chart for the status count\n",
    "plot_bar_chart(status_count, 'Next Release Predictions Based on PackageDistro Repository', 'Predictions for Next Release', 'Number of Packages')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing Data: Visualising Key Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of packages with tested versions, required version tested, both version tests and no tests\n",
    "ci_tests_count = 0\n",
    "pkg_tests_count = 0\n",
    "both_tests_count = 0\n",
    "no_tests_count = 0\n",
    "\n",
    "for package_info in repo_data:\n",
    "    package = package_info[\"repo\"]\n",
    "    if package in testing_data:\n",
    "        if \"tested_ci_versions\" in testing_data[package]:\n",
    "            ci_tests_count += 1\n",
    "        if \"required_pkginfo_version\" in testing_data[package]:\n",
    "            pkg_tests_count += 1\n",
    "        if \"tested_ci_versions\" in testing_data[package] and \"required_pkginfo_version\" in testing_data[package]:\n",
    "            both_tests_count += 1\n",
    "    else:\n",
    "        no_tests_count += 1\n",
    "\n",
    "categories = [\"Tested Versions\", \"Required Test Version\", \"Both Test Formats\", \"No Test Formats\"]\n",
    "counts = [ci_tests_count, pkg_tests_count, both_tests_count, no_tests_count]\n",
    "\n",
    "plot_bar_chart(\n",
    "    data=dict(zip(categories, counts)),\n",
    "    title='Number of GAP Packages with Tested Versions in CI and Required PackageInfo Version',\n",
    "    x_label='Categories',\n",
    "    y_label='Counts'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation between number of test files and lines of test code\n",
    "test_line_count = {}\n",
    "test_file_count = {}\n",
    "\n",
    "for package, data in testing_data.items():\n",
    "    if \"tst_file_count\" in data:\n",
    "        test_file_count[package] = data[\"tst_file_count\"]\n",
    "    if \"total_lines_in_tst_files\" in data:\n",
    "        test_line_count[package] = data[\"total_lines_in_tst_files\"]\n",
    "\n",
    "# Convert data to numpy arrays for calculations\n",
    "num_test_files = np.array(list(test_file_count.values()))\n",
    "total_lines_test_files = np.array(list(test_line_count.values()))\n",
    "\n",
    "# Calculate correlation coefficient between test file count and test line count\n",
    "correlation_coefficient = np.corrcoef(num_test_files, total_lines_test_files)[0, 1]\n",
    "\n",
    "# Create a scatter plot with linear regression line and confidence interval of 50%\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.regplot(x=num_test_files, y=total_lines_test_files, color='#ff9934', ci=50, label=\"Data Points\")\n",
    "\n",
    "# Provide labels and create the plot \n",
    "plt.text(0.98, 0.03, \"Linear Regression Line\\nand Confidence Interval (50%)\", transform=plt.gca().transAxes, \n",
    "         fontsize=12, color=\"#ff9934\", ha='right', va='bottom')\n",
    "plt.xlabel(\"Number of Test Files\")\n",
    "plt.ylabel(\"Total Lines in Test Files\")\n",
    "plt.title(f\"Correlation between Test Files and Lines of Test Code\\nCorrelation Coefficient: {correlation_coefficient:.2f}\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Community Data: Visualising Key Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define community data for visualisation\n",
    "authors = community_data['authors']\n",
    "submitters = community_data['submitters']\n",
    "author_submitters = community_data['author_submitters']\n",
    "author_repo_counts = community_data['author_repo_counts']\n",
    "interactions = community_data['interactions']\n",
    "first_author_commit = community_data['first_commit_by_author']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to show the number of users who are authors, submitters and both authors and submitters\n",
    "count_contributor_labels = {\n",
    "    \"Authors\": len(authors),\n",
    "    \"Submitters\": len(submitters),\n",
    "    \"Author-Submitters\": len(author_submitters)\n",
    "}\n",
    "\n",
    "plot_bar_chart(\n",
    "    data=count_contributor_labels,\n",
    "    title='Number of Authors, Issue Submitters and Author-Submitters',\n",
    "    x_label='Contributor Type',\n",
    "    y_label='Count'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top authors and the number of their repository contributions\n",
    "sorted_contributors = sorted(author_repo_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "top_contributors = dict(sorted_contributors[:top_n_users])\n",
    "\n",
    "# Get labels for displaying top authors using label function\n",
    "labels_dict = create_author_labels({author: 0 for author in top_contributors})\n",
    "top_contributor_labels = [labels_dict[author] for author in top_contributors]\n",
    "data_with_labels = {labels_dict[author]: count for author, count in top_contributors.items()}\n",
    "\n",
    "plot_bar_chart(\n",
    "    data=data_with_labels,\n",
    "    title=f'Top {top_n_users} Authors and Their Repository Contributions',\n",
    "    x_label='Authors',\n",
    "    y_label='Repository Contribution Count'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to show the top authors with the most other users submitting issues to their repos\n",
    "top_authors = sorted(interactions.keys(), key=lambda k: len(interactions[k]), reverse=True)[:top_n_users]\n",
    "interactions_count = [len(interactions[author]) for author in top_authors]\n",
    "\n",
    "# Get labels for top authors using label generator function\n",
    "labels_dict = create_author_labels({author: 0 for author in top_authors})\n",
    "top_author_labels = [labels_dict[author] for author in top_authors]\n",
    "\n",
    "plot_bar_chart(\n",
    "    data={labels_dict[author]: len(interactions[author]) for author in top_authors},\n",
    "    title=f'Top {top_n_users} Authors with Most Issue Submitter Interactions',\n",
    "    x_label='Authors',\n",
    "    y_label='Interactions Count'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dynamic overview on the historic developments of contributor community based on first commit\n",
    "first_commit_years = {}\n",
    "for commit_date in first_author_commit.values():\n",
    "    if commit_date != \"No commits\":\n",
    "        year = int(commit_date[-4:])\n",
    "        first_commit_years[year] = first_commit_years.get(year, 0) + 1\n",
    "\n",
    "sorted_years = sorted(first_commit_years.items(), key=lambda x: x[0])\n",
    "years, counts = zip(*sorted_years)\n",
    "\n",
    "plot_bar_chart(\n",
    "    data=dict(zip(years, counts)),\n",
    "    title='Number of Contributors by Year of First Commit',\n",
    "    x_label='Year',\n",
    "    y_label='Number of Contributors'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a NetworkX plot to represent interactions between authors and contributers\n",
    "plot_collaborations(community_data, top_n_users)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Notebook For Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the script has been executed once and the outputs have been generated, it is very important to **save the file** before starting the Streamlit dashboard. If not, the outputs will not be available on the dashboard."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
